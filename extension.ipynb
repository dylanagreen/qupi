{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2a0ad26-04cc-4a36-8b07-7c78ba98d57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "from scipy.optimize import root_scalar\n",
    "from scipy.integrate import trapezoid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71af5c08-68fe-4d62-aa1d-0b6b9364fe16",
   "metadata": {},
   "source": [
    "In formalism.ipynb we investigated the basic outline of the paper. In this notebook we will extend the method a little bit, as noted in the conclusion. One of the ways proposed to improve this measurement of $\\pi$ is to use more than a single half period of the probability function to estimate $\\pi$. In this notebook I'll introduce some code that uses two half-periods per qubit to estimate $\\pi$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b8a9d0c-15be-4049-9de5-387bbff83051",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qubit:\n",
    "    def __init__(self, seed, alpha, beta, phi0, c):\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.phi0 = phi0\n",
    "        self.c = c\n",
    "        \n",
    "        self.prob = lambda t: alpha / 2 * (1 - np.cos(c * t + phi0)) + beta\n",
    "        \n",
    "        self.rng = np.random.default_rng(seed)\n",
    "        \n",
    "    def measure(self, t, n=1):\n",
    "        # The n parameter allows us to run multiple measurements for the same time step\n",
    "        # with one function call. This speeds up the computation a bit.\n",
    "        v = self.rng.random(size=n)\n",
    "        p = self.prob(t)\n",
    "        \n",
    "        # \"less than\" ensures the probability actually works as intended\n",
    "        return np.where(v < p, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932013c0-a54b-4b5c-9366-def5158e24bb",
   "metadata": {},
   "source": [
    "Must of this following code remains the same as before, so I've kept it the same up to the point where things change, at which point I'll introduce some commentary. The first obvious change is that we're going to need to get to at least $3\\pi$ in time steps, so I'll just call it an even 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df1d5115-b354-4bae-8073-df2cc38b74a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding qubit with seed 0\n",
      "0.9998779296875 0.0\n",
      "Adding qubit with seed 12\n",
      "0.999755859375 0.0\n",
      "Adding qubit with seed 24\n",
      "1.0 0.0\n",
      "Adding qubit with seed 15\n",
      "0.9998779296875 0.0\n",
      "Adding qubit with seed 27\n",
      "0.999755859375 0.0\n"
     ]
    }
   ],
   "source": [
    "time_steps = np.arange(0, 10, 0.1)\n",
    "\n",
    "q = {}\n",
    "f = {}\n",
    "f1 = {}\n",
    "f1_interp = {}\n",
    "alpha_hat = {}\n",
    "beta_hat = {}\n",
    "\n",
    "for i in range(5):\n",
    "    seed = 5 * i + 7 * (i % 3)\n",
    "    print(f\"Adding qubit with seed {seed}\")\n",
    "    q[i] = Qubit(seed, 1, 0, 0, 1)\n",
    "    \n",
    "    \n",
    "    vals = []\n",
    "    n_measure = 8192\n",
    "    for t in time_steps:\n",
    "        m = q[i].measure(t, n_measure)\n",
    "        frac = np.sum(m) / len(m)\n",
    "        vals.append(frac)\n",
    "\n",
    "    f[i] = np.asarray(vals)\n",
    "\n",
    "    beta_hat[i] = np.min(f[i])\n",
    "    alpha_hat[i] = np.max(f[i]) - beta_hat[i]\n",
    "\n",
    "    f1[i] = (f[i] - beta_hat[i]) / alpha_hat[i]\n",
    "    f1_interp[i] = lambda x: np.interp(x, time_steps, f1[i])\n",
    "\n",
    "    print(alpha_hat[i], beta_hat[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d569ff9-950e-4c48-97bd-7c56d72a4aa3",
   "metadata": {},
   "source": [
    "As before, Nwe want to find where $\\tilde{f_1} \\approx 0.5$, except now instead of being just close to $t_1 = 1.5$ and $t_2 = 4.5$ we also seek where it's close to $t_3=8$. As before I define an $f_2$ interpolation that is simply $f_1 - 0.5$ for root finding purposes, since the root finder looks for 0's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32e73218-7d47-4648-b8d5-3831a323071c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5726506024096387 4.690212264150944 7.861341463414635\n",
      "1.573396674584323 4.726566416040101 7.855621301775149\n",
      "1.5894021739130435 4.7131336405529956 7.856474820143886\n",
      "1.5715533980582526 4.7022300469483564 7.864319809069213\n",
      "1.5818791946308726 4.691688311688312 7.855480984340044\n"
     ]
    }
   ],
   "source": [
    "t1 = {}\n",
    "t2 = {}\n",
    "t3 = {}\n",
    "\n",
    "for i in range(len(q)):\n",
    "    f2 = lambda x: np.interp(x, time_steps, f1[i]) - 0.5\n",
    "\n",
    "    t1[i] = root_scalar(f2, x0=1.5, x1=2).root\n",
    "    t2[i] = root_scalar(f2, x0=4.5, x1=5).root\n",
    "    t3[i] = root_scalar(f2, x0=7.6, x1=8).root\n",
    "\n",
    "    print(t1[i], t2[i], t3[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f91f03-33de-4ba5-8225-dcceca154cc7",
   "metadata": {},
   "source": [
    "Next steps are the same as before, where we estimate and refine $\\hat{\\alpha}$ and $\\hat{\\beta}$, except this time we no longer have to vaguely estimate $t_{minval}$ from $t_1$ and $t_2$, this time we can know it must be between $t_2$ and $t_3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d8b0da5-e54c-400e-917e-594953141845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9998779296875 -2.3900922930516827e-07\n",
      "New times 1.5648532188189983 4.703886542866155 7.856003984615389\n",
      "0.9997558593749999 -6.577580254126664e-07\n",
      "New times 1.5695339742117738 4.716952338985774 7.855642278423961\n",
      "1.0 0.0\n",
      "New times 1.5769093482675858 4.713788798816388 7.854594163418265\n",
      "0.9998779296875001 -1.4933967069257533e-07\n",
      "New times 1.5696075355981445 4.709468270668766 7.850838258702262\n",
      "0.999755859375 -2.6876211019433377e-07\n",
      "New times 1.5752135393827447 4.707112017461871 7.854356267390136\n"
     ]
    }
   ],
   "source": [
    "delta = 0.1\n",
    "t1_hat = {}\n",
    "t2_hat = {}\n",
    "t3_hat = {}\n",
    "\n",
    "for i in range(len(q)):\n",
    "    t_maxval = (t1[i] + t2[i]) / 2\n",
    "    t_minval = (t2[i] + t3[i]) / 2\n",
    "\n",
    "    # Indices of time steps that satisfy this condition\n",
    "    tmax = np.where(np.abs((time_steps - t_maxval)) < delta)[0]\n",
    "    tmin = np.where(np.abs((time_steps - t_minval)) < delta)[0]\n",
    "\n",
    "    beta_hat[i] = np.mean(f1[i][tmin])\n",
    "    alpha_hat[i] = np.mean(f1[i][tmax]) - beta_hat[i]\n",
    "\n",
    "    f1[i] = (f[i] - beta_hat[i]) / alpha_hat[i]\n",
    "    f1_interp[i] = lambda x: np.interp(x, time_steps, f1[i])\n",
    "\n",
    "    print(alpha_hat[i], beta_hat[i])\n",
    "    \n",
    "    # Indices of time steps that fulfill the above condition.\n",
    "    t1_idx = np.where(np.abs((time_steps - t1[i])) < 0.5)[0]\n",
    "    coeff_1 = np.polyfit(time_steps[t1_idx], f1[i][t1_idx], 1)\n",
    "\n",
    "    # Once again subtracting 0.5 to find where the function = 0.5 not 0.\n",
    "    fit_1 = lambda x: coeff_1[0] * x + coeff_1[1] - 0.5\n",
    "    t1_hat[i] = root_scalar(fit_1, x0=1.5, x1=2).root\n",
    "\n",
    "    # Indices of time steps that fulfill the above condition.\n",
    "    t2_idx = np.where(np.abs((time_steps - t2[i])) < 0.5)[0]\n",
    "    coeff_2 = np.polyfit(time_steps[t2_idx], f1[i][t2_idx], 1)\n",
    "\n",
    "    # Once again subtracting 0.5 to find where the function = 0.5 not 0.\n",
    "    fit_2 = lambda x: coeff_2[0] * x + coeff_2[1] - 0.5\n",
    "    t2_hat[i] = root_scalar(fit_2, x0=4.5, x1=5).root\n",
    "    \n",
    "    # Indices of time steps that fulfill the above condition.\n",
    "    t3_idx = np.where(np.abs((time_steps - t3[i])) < 0.5)[0]\n",
    "    coeff_3 = np.polyfit(time_steps[t3_idx], f1[i][t3_idx], 1)\n",
    "\n",
    "    # Once again subtracting 0.5 to find where the function = 0.5 not 0.\n",
    "    fit_3 = lambda x: coeff_3[0] * x + coeff_3[1] - 0.5\n",
    "    t3_hat[i] = root_scalar(fit_3, x0=7.5, x1=8).root\n",
    "\n",
    "\n",
    "    print(\"New times\", t1_hat[i], t2_hat[i], t3_hat[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdd399e-f063-42b6-8143-45ca896d2509",
   "metadata": {},
   "source": [
    "Finaly we estimate the integral between $t_1$ and $t_2$ using the trapezoidal rule, which then gives us an estimate of $\\pi$ via $\\pi \\approx \\frac{t_2 - t_1}{I}$. This is the same as before, of course. However we must now include an additional step, and estimate the integral between $t_2$ and $t_3$ in order to get a second estimate from that time period. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9e55c0b-c9e0-4692-a789-b7b4d4814f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_guess_t1t2 = {}\n",
    "pi_guess_t2t3 = {}\n",
    "for i in range(len(q)):\n",
    "    f_hat = lambda x: np.interp(x, time_steps, f[i])\n",
    "\n",
    "    # Adding the t1 and t2 to the measured timesteps for integration purposes.\n",
    "    t_idx = np.where((time_steps >= t1[i]) & (time_steps <= t2[i]))[0]\n",
    "    t_integ = time_steps[t_idx]\n",
    "    t_integ = np.insert(t_integ, 0, t1_hat[i])\n",
    "    t_integ = np.append(t_integ, t2_hat[i])\n",
    "\n",
    "    # Doing the same for the probability measured values\n",
    "    y_integ = f[i][t_idx]\n",
    "    y_integ = np.insert(y_integ, 0, f_hat(t1_hat[i]))\n",
    "    y_integ = np.append(y_integ, f_hat(t2_hat[i]))\n",
    "\n",
    "    # Trapezoidal rule on the given points\n",
    "    I = np.trapz(y_integ - 0.5, t_integ)\n",
    "\n",
    "    # And the final guess!\n",
    "    pi_guess_t1t2[i] = (t2_hat[i] - t1_hat[i]) / I\n",
    "    \n",
    "    \n",
    "    # Adding the t2 and t3 to the measured timesteps for integration purposes.\n",
    "    t_idx = np.where((time_steps >= t2[i]) & (time_steps <= t3[i]))[0]\n",
    "    t_integ = time_steps[t_idx]\n",
    "    t_integ = np.insert(t_integ, 0, t2_hat[i])\n",
    "    t_integ = np.append(t_integ, t3_hat[i])\n",
    "\n",
    "    # Doing the same for the probability measured values\n",
    "    y_integ = f[i][t_idx]\n",
    "    y_integ = np.insert(y_integ, 0, f_hat(t2_hat[i]))\n",
    "    y_integ = np.append(y_integ, f_hat(t3_hat[i]))\n",
    "\n",
    "    # Trapezoidal rule on the given points\n",
    "    # We expect this one to be negative, so to estimate pi we will invert it to positve.\n",
    "    I = -np.trapz(y_integ - 0.5, t_integ)\n",
    "\n",
    "    # And the final guess!\n",
    "    pi_guess_t1t2[i] = (t2_hat[i] - t1_hat[i]) / I\n",
    "    pi_guess_t2t3[i] = (t3_hat[i] - t2_hat[i]) / I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e65c77a1-5ec6-40c2-a2fb-c33b0f0cad7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.139480440972794, 3.1445000131483054, 3.1419902270605498)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi_t1t2 = np.nanmean(list(pi_guess_t1t2.values()))\n",
    "pi_t2t3 = np.nanmean(list(pi_guess_t2t3.values()))\n",
    "\n",
    "pi_t1t2, pi_t2t3, np.mean((pi_t1t2, pi_t2t3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6d0e4b-be1a-40a2-bac7-def7bf5edb1e",
   "metadata": {},
   "source": [
    "Even extending the method in this simple way already massively improves our accuracy, although keep in mind again that we're working with \"ideal\" qubits, which have a \"perfect\" probability distribution for the $\\lvert 1 \\rangle$ state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab2fa3d-c8ef-45e9-9524-ceaf1e649f2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
